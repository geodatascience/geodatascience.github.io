<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<title>What We Tweet About ... - GeoDataScience</title>
<meta name="description" content="A blog about Geography, Data and Science. Indeed">
<meta name="viewport" content="width=device-width, initial-scale=1">



  <meta name="generator" content="Hugo 0.55.5" />
  
<meta itemprop="name" content="What We Tweet About ...">
<meta itemprop="description" content="What We Tweet About &hellip; Python
I recently discovered a very nice python lib called wordcloud and I wanted to play with it. I am writing this tutorial, after a couple of days of experimentation, to explain how to use wordcloud to generate a cloud of the most frequent #hashtags, extracted from twitter, related to a search query.
At the end of this tutorial, you should be able to generate the image above &ndash; the words on the image match the #hashtags related to &ldquo;gilets jaunes&rdquo; (yellow vest).">


<meta itemprop="datePublished" content="2019-05-18T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-05-18T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1111">



<meta itemprop="keywords" content="" />

  <meta property="og:title" content="What We Tweet About ..." />
<meta property="og:description" content="What We Tweet About &hellip; Python
I recently discovered a very nice python lib called wordcloud and I wanted to play with it. I am writing this tutorial, after a couple of days of experimentation, to explain how to use wordcloud to generate a cloud of the most frequent #hashtags, extracted from twitter, related to a search query.
At the end of this tutorial, you should be able to generate the image above &ndash; the words on the image match the #hashtags related to &ldquo;gilets jaunes&rdquo; (yellow vest)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://geodatascience.github.io/geodatascience_repo/blog/what_we_tweet_about/" />
<meta property="article:published_time" content="2019-05-18T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-05-18T00:00:00&#43;00:00"/>

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="What We Tweet About ..."/>
<meta name="twitter:description" content="What We Tweet About &hellip; Python
I recently discovered a very nice python lib called wordcloud and I wanted to play with it. I am writing this tutorial, after a couple of days of experimentation, to explain how to use wordcloud to generate a cloud of the most frequent #hashtags, extracted from twitter, related to a search query.
At the end of this tutorial, you should be able to generate the image above &ndash; the words on the image match the #hashtags related to &ldquo;gilets jaunes&rdquo; (yellow vest)."/>

  

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css">
  
    
      <link rel="stylesheet" href="/geodatascience_repo/css/normalize.css">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.1.0/css/flag-icon.min.css">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
      <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.10/css/all.css" integrity="sha384-+d0P83n9kaQMCwj8F4RJB66tzIwOKmrdb46+porD/OvrJ+37WqIM7UoBtwHO6Nlg" crossorigin="anonymous">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.css" />
      <link rel="stylesheet" href="/geodatascience_repo/css/main.min.css">
      <link rel="stylesheet" href="/geodatascience_repo/css/add-on.css">
    
  
  
</head>

  <body>
    
<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/geodatascience_repo/">
        
          
            Blog
          
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu">
      
        <a href="/geodatascience_repo" class="link"><i class="fas fa-home">&nbsp;</i>Home</a>
      
        <a href="/geodatascience_repo/about/" class="link"><i class="far fa-id-card">&nbsp;</i>About</a>
      
        <a href="/geodatascience_repo/blog/" class="link"><i class="far fa-newspaper">&nbsp;</i>Blog</a>
      
        <a href="/geodatascience_repo/categories/" class="link"><i class="fas fa-sitemap">&nbsp;</i>Categories</a>
      
        <a href="/geodatascience_repo/contact/" class="link"><i class="far fa-envelope">&nbsp;</i>Contact</a>
      
      <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      

    </menu>
    

    <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="lang-toggle" lang="en"><span class="flag-icon flag-icon-en" alt="en"></span></a>
    <a href="#site-nav" class="nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="lang-menu" class="flyout-menu">
  <a href="#" lang="en" class="active"><span class="flag-icon flag-icon-en" alt="en"></span></a>
  
    
      
    
      
        <a href="/fr" lang="fr" class="no-lang"><span class="flag-icon flag-icon-fr" alt="fr"></span></a>
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu">
      <h1>Share Post</h1>
      



  
    <a href="//twitter.com/share?url=&amp;text=&amp" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=&amp;title=" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  

  
        <a href="mailto:?subject=Check out this post by &amp;body=" target="_blank" class="share-btn email">
          <i class="fas fa-envelope"></i><p>&nbsp;Email</p>
        </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro">
  <a href="/geodatascience_repo/"><img src="/geodatascience_repo/img/main/logo.png" class="circle" width="" alt="GeoDataScience" /></a>
  <header>
    <h1>GeoDataScience</h1>
  </header>
  <main>
    <p>A blog about Geography, Data and Science. Indeed</p>
  </main>
  
    <footer>
      <ul class="social-icons">
        

        






































      </ul>
    </footer>
  
</section>

      <main id="site-main">
        <article class="post">
  <header>
  <div class="title">
    
        <h2><a href="/geodatascience_repo/blog/what_we_tweet_about/">What We Tweet About ...</a></h2>
    
    
</div>
  <div class="meta">
    <time class="published" datetime="2019-05-18 00:00:00 &#43;0000 UTC">
      May 18, 2019
    </time>
    <span class="author">Patrick S. Kanmeugne</span>
    
        <p>6 minute read</p>
    
  </div>
</header>

  <section id="social-share">
    



  
    <a href="//twitter.com/share?url=&amp;text=&amp" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=&amp;title=" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  

  
        <a href="mailto:?subject=Check out this post by &amp;body=" target="_blank" class="share-btn email">
          <i class="fas fa-envelope"></i><p>&nbsp;Email</p>
        </a>
  


  </section>
  

  <div class="content">
    

<h1 id="what-we-tweet-about">What We Tweet About &hellip;</h1>

<p>Python</p>

<p>I recently discovered a very nice python lib called <a href="https://amueller.github.io/word_cloud/" title="WordCloud for Python documentation">wordcloud</a> and I wanted to play with it. I am writing this tutorial, after a couple of days of experimentation, to explain how to use <code>wordcloud</code> to generate a cloud of the most frequent <strong>#hashtags</strong>, extracted from twitter, related to a search query.</p>

<p><img src="../../img/2019/05/fr_giletsjaunes.png" width=10% markdown="1" title="the most popular #hashtags related to 'gilets jaunes', generated on the 20th of May 2019"/></p>

<p>At the end of this tutorial, you should be able to generate the image above &ndash; the words on the image match the <strong>#hashtags</strong> related to &ldquo;<em>gilets jaunes</em>&rdquo; (<a href="https://en.wikipedia.org/wiki/Yellow_vests_movement">yellow vest</a>).</p>

<p>The main steps can be listed as follows :</p>

<ol>
<li><strong>Search query execution (through the Twitter API)</strong></li>
<li><strong>Hashtags extraction (+ Frequency map construction)</strong></li>
<li><strong>Wordcloud creation (from a frequency map) + Image generation</strong></li>
</ol>

<h2 id="first-things-first-the-python-environment">First things first : the python environment</h2>

<p>First of all, I have to admit that <a href="https://amueller.github.io/word_cloud/" title="WordCloud for Python documentation">wordcloud</a> is not the only python library I used. Here is the complete set of dependencies :</p>

<ul>
<li><a href="https://www.numpy.org" title="NumPy is the fundamental package for scientific computing with Python.">numpy</a> : to manipulate arrays of pixels.</li>
<li><a href="https://github.com/ryanmcgrath/twython" title="Actively maintained, pure Python wrapper for the Twitter API">twython</a> : to search for tweets</li>
<li><a href="https://docs.python.org/2/library/re.html," title="Regular expression operations">re</a> : to parse the tweets.</li>
<li><a href="https://pillow.readthedocs.io/en/stable/" title="Python Imaging Library">PIL</a> : to turn an image into an array of pixels.</li>
</ul>

<p>NB: You would probably make a great use of <a href="https://virtualenv.pypa.io/en/latest/" title="virtualenv is a tool to create isolated Python environments">virtualenv</a> in other to work in a dedicated and clean environment.</p>

<h2 id="step-1-search-query-execution-through-the-twitter-api">Step 1. Search query execution (through the Twitter API)</h2>

<p>You need to apply for access tokens from the twitter dev platform to be able to use their research API &ndash; the standard (free) plan is sufficient for this tutorial (please refer to <a href="https://developer.twitter.com/en/apply-for-access" title="All new developers must apply for a developer account to access Twitter APIs. Once approved, you can begin to use our standard APIs and our new premium APIs.">their website</a> and come back when you are done). Save your credentials - <code>CONSUMER_KEY</code>, <code>CONSUMER_SECRET</code>, <code>ACCESS_TOKEN</code>, <code>ACCESS_SECRET</code> - as a json file somewhere in your disk.</p>

<p>I suggest you the following function - <code>collectAndSaveTweets</code> - to collect and save your tweets. Here is a simple description of the most important parameters of <code>collectAndSaveTweets</code>:</p>

<ul>
<li><code>searchtoken</code> : the keywords to search for</li>
<li><code>credentialfilepath</code> : you credential file path (<code>json</code> format)</li>
<li><code>tweetfilepath</code> : where you want to save your tweets (<code>text</code> file)</li>
<li><code>language</code> : search for tweet in this specific language</li>
</ul>

<pre><code class="language-python">import json
from twython import Twython
def collectAndSaveTweets(
    searchtoken,
    credentialfilepath,
    tweetfilepath,
    maxattempts,
    nboftweetstobefetch,
    language
):
    # credential parameters
    with open(credentialfilepath, mode='r') as f:
        d = json.load(f)

    # session object
    api = Twython(d['CONSUMER_KEY'], d['CONSUMER_SECRET'],
               d['ACCESS_TOKEN'], d['ACCESS_SECRET'])

    # Check if the connexion is successful
    api.verify_credentials()

    # file that holds the tweets
    tweetfile = open(tweetfilepath, 'w')

    # tweet count
    tweets = 0

    # apply a search query using the API
    for i in range(0, maxattempts):

        if(nboftweetstobefetch &lt; tweets):
            break

        # Query Twitter:
        if(0 == i):
            results = api.search(
                q=searchtoken,
                count=1000,
                lang=language,
                tweet_mode='extended'
            )
        else:
            # After the first call we should have
            # max_id from result of previous call.
            # Pass it in query. Use the extended mode to get
            # all the content of the tweet and not a truncated version.
            results = api.search(
                q=searchtoken,
                include_entities='true',
                max_id=next_max_id,
                tweet_mode='extended'
            )

        # Save the returned tweets :
        # Tweets content are truncated
        # (even in the extended mode) when retweeted.
        # If it is the case, the full text of the
        # original tweet is in the retweeted_status
        # field of the JSON response.
        for result in results['statuses']:
            if 'retweeted_status' in result:
                tweetfile.write(result['retweeted_status']['full_text'])
            else:
                tweetfile.write(result['full_text'])
            tweets += 1

        # Get the next max_id to iterate over the results:
        try:
            next_results_url_params = results['search_metadata']['next_results']
            next_max_id = next_results_url_params.split('max_id=')[1].split('&amp;')[0]
        except:
            break

    # close the file thats holds the tweets
    tweetfile.close()
</code></pre>

<p>Everything should be fine from here if you have properly created your access tokens.</p>

<p>You should be able to try some queries and see the results in a text file (remember that the language is very important - see <a href="https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes" title="List of ISO 639 codes">here</a> for details)</p>

<h2 id="step-2-hashtags-extraction-frequency-map-construction">Step 2. Hashtags extraction (+ Frequency map construction)</h2>

<p>In order to use <a href="https://amueller.github.io/word_cloud/" title="WordCloud for Python documentation">wordcloud</a>, you will need to generate a word frequency map. My suggestion is to use the function <code>getFrequencyDictForText</code> below. The function takes a text and a filter object &ndash; defined by <code>FilterObj</code> class &ndash; as parameters and builds the frequency map for the hashtags (in the input text) that satisfy a given filtering condition.</p>

<p>You will have all the freedom to define your filtering condition in the <code>__call__</code> function of the <code>FilterObj</code> object.</p>

<pre><code class="language-python">import re
def getFrequencyDictForText(fulltext, filterobj):
    result = {}
    for textblock in re.split('[\s\n,\.]+', fulltext):
        if filterobj(textblock):
            val = result.get(textblock.lower()[1:], 0)
            result[textblock.lower()[1:]] = val + 1
    return result

# The filter object (we can easily modify it according to our need).
class FilterObj(object):
    def __init__(self, *tabuwords):
        self.__tabuwords = tabuwords
    def __call__(self, text):
        isnotin = lambda tabu: (text.lower().find(tabu)==-1)
        return re.match(&quot;^#&quot;, text) and all(map(isnotin, self.__tabuwords))
</code></pre>

<p>We are going to call this function on the full content of our tweets file and generate a frequency map. Then we will process the frequency map in other to generate the cloud that we want. This is where <code>wordcloud</code> comes into the game.</p>

<h2 id="step-3-wordcloud-creation-from-a-frequency-map-image-generation">Step 3. Wordcloud creation (from a frequency map) + Image generation</h2>

<p>The function <code>makeImage</code> is the last ingredient for our cloud creation process. It takes a frequency map and turns it into an image with the help of <code>wordcloud</code>. Below, a simple description of the most important parameters of <code>makeImage</code>:</p>

<ul>
<li><code>tweetsfrequencymap</code> : the frequency map of the hashtags related to our query. They should have been processed according to our needs (see the previous section)</li>
<li><code>pathtomask</code> : the path to the black an white image that will be used to bound the cloud (the map of France in the example above)</li>
<li><code>outputpath</code> : the output path for the resulting image</li>
<li><code>backgroundcolor</code> : the backgroud color of the image</li>
<li><code>contourcolor</code> : the color of the boundaries</li>
<li><code>contourwith</code> : the thickness of the boundaries</li>
</ul>

<pre><code class="language-python">import numpy as np
import wordcloud
from PIL import Image
def makeImage(
    tweetsfrequencymap,
    pathtomask,
    outputpath,
    contourwidth=3,
    backgroundcolor='white',
    contourcolor='black'
):
    mask = np.array(Image.open(pathtomask, mode='r'))
    wc = WordCloud(
        background_color=background_color,
        mask=mask,
        contour_width=contourwidth,
        contour_color=contourcolor
    )
    # generate word cloud
    wc.generate_from_frequencies(tweetsfrequencymap)
    wc.to_file(outputpath)
</code></pre>

<p>Voila! Put all these functions (and the class definition of <code>FilterObj</code>) in a python file and add the following lines of code at the end. You are ready to roll !</p>

<pre><code class="language-python">
if __name__ == '__main__':

    # keywords to search for
    SEARCHTOKEN = input('enter the search token:')

    # global parameters
    PATHTOTHEJSONFILE = &quot;./credentials.json&quot;
    TWEETSFILEPATH = &quot;./tweets.txt&quot;
    MASKIMAGEPATH = &quot;./temporary/test.png&quot;
    OUTPUTPATH = &quot;output.png&quot;
    LANG = &quot;fr&quot;

    # collect and save the tweets
    collectAndSaveTweets(
        SEARCHTOKEN,
        PATHTOTHEJSONFILE,
        TWEETSFILEPATH,
        language=LANG
    )

    # build a frequency map from the tweets
    tweetfile = open(TWEETSFILEPATH, mode='r')
    fulltext = tweetfile.read()
    filterobj = FilterObj(*re.split('\s', SEARCHTOKEN))

    # generate cloud and save into image
    makeImage(
        getFrequencyDictForText(fulltext, filterobj),
        maskimagepath=MASKIMAGEPATH,
        outputpath=OUTPUTPATH
    )
</code></pre>

<p>I have used this worflow to generate several #hashtags clouds. You will find some examples at the end of the document.</p>

<p>I you have enjoyed this article. Feel free to send us some comments.</p>

<p>Patrick S. Kanmeugne <em>for geodatascience.io</em></p>

<p>{::nomarkdown}
<img src="../../img/2019/05/fr_emmanuelmacron.png" width=50% title="the most popular #hashtags related to 'emmanuel macron', generated on the 15st of May 2019"/>
<img src="../../img/2019/05/fr_nathalieloiseau.png" width=50% markdown="1" title="the most popular #hashtags related to 'nathalie loiseau', generated on the 15st of May 2019"/>
<img src="../../img/2019/05/us_donaldtrump.png" width=50% markdown="1" title="the most popular #hashtags related to 'donald trump', generated on the 15st of May 2019"/>
<img src="../../img/2019/05/fr_epitech.png" width=50% markdown="1" title="the most popular #hashtags related to <<epitech>&gt;, generated on the 15st of May 2019&rdquo;/&gt;
{:/}</p>

  </div>
  <footer>
    <ul class="stats">
  
    
    
      <li class="categories">
        <ul>
          
            
            <li><a class="article-category-link" href="https://geodatascience.github.io/geodatascience_repo/categories/wordcloud">Wordcloud</a></li>
          
            
            <li><a class="article-category-link" href="https://geodatascience.github.io/geodatascience_repo/categories/hastag">Hastag</a></li>
          
            
            <li><a class="article-category-link" href="https://geodatascience.github.io/geodatascience_repo/categories/twitter">Twitter</a></li>
          
            
            <li><a class="article-category-link" href="https://geodatascience.github.io/geodatascience_repo/categories/python">Python</a></li>
          
        </ul>
      </li>
    
  
  
    <li class="tags">
      <ul>
        <li>None</li>
      </ul>
    </li>
  
</ul>

  </footer>
</article>
<article class="post">
  

</article>
<div class="pagination">
  
  
    <a href="/geodatascience_repo/blog/welcome/" class="button big next">Welcome <i class="fas fa-angle-right"></i></a>
  
</div>


      </main>
      <section id="site-sidebar">
  <section id="recent-posts">
    <header>
      <h1>Recent posts</h1>
    </header>
    
    <article class="mini-post">
      <section>
        

      </section>
      <header>
        <h1><a href="/geodatascience_repo/blog/welcome/">Welcome</a></h1>
        <time class="published" datetime="">May 20, 2019</time>
      </header>
    </article>
    
    <article class="mini-post">
      <section>
        

      </section>
      <header>
        <h1><a href="/geodatascience_repo/blog/what_we_tweet_about/">What We Tweet About ...</a></h1>
        <time class="published" datetime="">May 18, 2019</time>
      </header>
    </article>
    
    
  </section>

  
    
      <section id="categories">
        <header>
          <h1><a href="/geodatascience_repo/categories">Categories</a></h1>
        </header>
        <ul>
          
            
          
          
          <li>
            
              <a href="/geodatascience_repo/categories/hastag/">hastag<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/geodatascience_repo/categories/misc/">misc<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/geodatascience_repo/categories/presentation/">presentation<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/geodatascience_repo/categories/python/">python<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/geodatascience_repo/categories/twitter/">twitter<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/geodatascience_repo/categories/wordcloud/">wordcloud<span class="count">1</span></a>
            
          
          </li>
        </ul>
      </section>
    
  

  <section id="mini-bio">
    <header>
      <h1>About</h1>
    </header>
    <p>test</p>
    <footer>
      <a href="/geodatascience_repo/about" class="button">Learn More</a>
    </footer>
  </section>
</section>

      <footer id="site-footer">
  
      <ul class="social-icons">
        

        






































      </ul>
  
  <p class="copyright">
    
      &copy; 2019
      
        GeoDataScience
      
    .
    Powered by <a href="//gohugo.io" target="_blank" rel="noopener">Hugo</a>
  </p>
</footer>
<a id="back-to-top" href="#" class="fas fa-arrow-up fa-2x"></a>

      
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/html.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/css.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/js.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/toml.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>


  
  <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/skel/3.0.1/skel.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.js"></script>
  <script src=/geodatascience_repo/js/util.js></script>
  <script src=/geodatascience_repo/js/main.js></script>
  <script src=/geodatascience_repo/js/add-on.js></script>
  



    </div>
  </body>
</html>
